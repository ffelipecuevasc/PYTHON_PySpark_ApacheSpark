# PYTHON_PySpark_ApacheSpark

Este repositorio contiene proyectos desarrollados en Python que permiten practicar la gesti贸n y an谩lisis de datos con Apache Spark, utilizando Jupyter Notebooks en Google Colab como entorno interactivo.

#  Contenido del Repositorio

El repositorio incluye dos notebooks dise帽ados de forma pedag贸gica para introducir progresivamente conceptos clave del ecosistema Apache Spark:

## 1锔 Apache Spark RDD.ipynb

Conexi贸n a Apache Spark y trabajo con RDDs

Este notebook explica:

- C贸mo inicializar una sesi贸n de Spark (SparkSession) en Google Colab.
- C贸mo cargar datos desde un archivo CSV.
- C贸mo asignar los datos a un RDD (Resilient Distributed Dataset).
- Casos de uso simples para entender el procesamiento distribuido basado en RDDs.

 Ideal para quienes est谩n comenzando con PySpark y desean comprender el enfoque m谩s b谩sico de procesamiento de datos.

## 2锔 Apache Spark DF SQL.ipynb

Spark SQL, DataFrames y Motores de Optimizaci贸n

Este notebook avanza hacia un enfoque m谩s estructurado con:

- Configuraci贸n de SparkSession.
- Carga de datos desde CSV directamente en un DataFrame.
- Uso de consultas SQL sobre DataFrames con spark.sql().
- Creaci贸n de funciones en Python registradas como UDFs (User Defined Functions) en el contexto SQL.
- Explicaci贸n de los motores de optimizaci贸n internos de Apache Spark:
  -  **Catalyst:** optimizaci贸n l贸gica y reescritura de planes de ejecuci贸n SQL.
  - 锔 **Tungsten:** mejoras f铆sicas a nivel de memoria y ejecuci贸n.

 Este segundo notebook es ideal para quienes desean avanzar en el uso eficiente de Spark SQL y comprender c贸mo Spark optimiza sus operaciones internas.
